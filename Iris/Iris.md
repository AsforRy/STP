
# ğŸŒ¸ Iris è³‡æ–™åˆ†æèˆ‡åˆ†é¡æ¨¡å‹ç¯„ä¾‹

æœ¬ç¯„ä¾‹ä»¥ç¶“å…¸çš„ Iris èŠ±å‰è³‡æ–™é›†ï¼Œå¯¦ä½œè³‡æ–™å‰è™•ç†ã€æ¢ç´¢æ€§è³‡æ–™åˆ†æã€æ¨¡å‹è¨“ç·´èˆ‡æ··æ·†çŸ©é™£è©•ä¼°ã€‚

---

## 1ï¸âƒ£ è³‡æ–™è¼‰å…¥èˆ‡åˆæ­¥æª¢æŸ¥

```python
df = pd.read_csv('Iris.csv')
df = df.drop(columns=["Id"])
df.head()
df.describe()
df.info()
```

---

## 2ï¸âƒ£ è³‡æ–™é è™•ç†

```python
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['Species'] = le.fit_transform(df['Species'])
df.isnull().sum()
```

- LabelEncoder å°‡èŠ±ç¨®è½‰æˆæ•¸å­— 0, 1, 2
- æª¢æŸ¥ç¼ºå¤±å€¼ï¼šçš†ç‚º 0ï¼Œè³‡æ–™å®Œæ•´

---

## 3ï¸âƒ£ æ¢ç´¢æ€§è³‡æ–™åˆ†æï¼ˆEDAï¼‰

### ğŸ”¢ æ•¸å€¼åˆ†å¸ƒï¼ˆç›´æ–¹åœ–ï¼‰

```python
df['SepalLengthCm'].hist()
df['SepalWidthCm'].hist()
df['PetalLengthCm'].hist()
df['PetalWidthCm'].hist()
```

### ğŸŒˆ ç‰¹å¾µé—œä¿‚åœ–ï¼ˆæ•£ä½ˆåœ–ï¼‰

```python
plt.scatter(df['SepalLengthCm'], df['SepalWidthCm'], c=colors)
```

- å¤šç¨®æ•£ä½ˆåœ–å±•ç¤ºèŠ±è¼ã€èŠ±ç“£çš„å¹¾ä½•ç‰¹å¾µ

---

## 4ï¸âƒ£ ç‰¹å¾µç›¸é—œæ€§åˆ†æ

```python
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
```

- é«˜ç›¸é—œï¼šPetalLengthCm vs PetalWidthCm

---

## 5ï¸âƒ£ æ©Ÿå™¨å­¸ç¿’æ¨¡å‹è¨“ç·´

```python
X = df.drop(columns=['Species'])
Y = df['Species']
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.4)
```

### ğŸ¤– æ¨¡å‹å»ºæ§‹èˆ‡è¨“ç·´

```python
# Logistic Regression
model1 = LogisticRegression()
model1.fit(x_train, y_train)

# K-Nearest Neighbors
model2 = KNeighborsClassifier()
model2.fit(x_train, y_train)

# Decision Tree
model3 = DecisionTreeClassifier()
model3.fit(x_train, y_train)
```

---

## 6ï¸âƒ£ æ¨¡å‹è©•ä¼°ï¼šæº–ç¢ºç‡

```python
print(model1.score(x_test, y_test))
print(model2.score(x_test, y_test))
print(model3.score(x_test, y_test))
```

---

## 7ï¸âƒ£ æ··æ·†çŸ©é™£ï¼ˆConfusion Matrixï¼‰

```python
confusion_matrix(y_test, model.predict(x_test))
sns.heatmap(...)
```

- è¦–è¦ºåŒ–ä¸‰å€‹æ¨¡å‹çš„é æ¸¬æº–ç¢ºæ€§
- åˆ†æåˆ†é¡éŒ¯èª¤é¡å‹èˆ‡æ•¸é‡

---

## âœ… å°çµ

- è³‡æ–™æ¸…æ´— â†’ è¦–è¦ºåŒ– â†’ æ¨¡å‹è¨“ç·´ â†’ è©•ä¼°æµç¨‹å®Œæ•´
- é©åˆä½œç‚ºæ©Ÿå™¨å­¸ç¿’åˆ†é¡å…¥é–€ç·´ç¿’

## âœ… æ¨¡å‹æ¯”è¼ƒç¸½çµï¼ˆä¸€èˆ¬æƒ…æ³ä¸‹çš„è¡¨ç¾ï¼‰

| æ¨¡å‹                      | å„ªé»                      | ç¼ºé»                 |
| ----------------------- | ----------------------- | ------------------ |
| **Logistic Regression** | è¨ˆç®—å¿«ï¼Œé©åˆç·šæ€§å¯åˆ†å•é¡Œï¼›å¯è§£é‡‹æ€§å¼·      | é‡åˆ°éç·šæ€§é‚Šç•Œæ•ˆæœå·®         |
| **K-Nearest Neighbors** | ç°¡å–®ç›´è§€ã€éåƒæ•¸å¼æ–¹æ³•ï¼›èƒ½è™•ç†éç·šæ€§é—œä¿‚    | å¤§è³‡æ–™æ…¢ã€å°é›œè¨Šæ•æ„Ÿã€ä¸é©åˆé«˜ç¶­è³‡æ–™ |
| **Decision Tree**       | å¯è™•ç†éç·šæ€§ã€å¯è¦–åŒ–ã€èƒ½è™•ç†é¡åˆ¥èˆ‡æ•¸å€¼æ··åˆè³‡æ–™ | å®¹æ˜“éæ“¬åˆï¼Œå°¤å…¶æ˜¯æ²’æœ‰é™åˆ¶æ·±åº¦æ™‚   |

## ğŸ§  ç¸½çµå»ºè­°

| å¦‚æœ...                | é¸ç”¨é€™å€‹æ¨¡å‹              |
| -------------------- | ------------------- |
| ä½ è¦å¿«é€Ÿå»ºç«‹åŸºæº–æ¨¡å‹ï¼ˆbaselineï¼‰ | Logistic Regression |
| ä½ æƒ³æ•æ‰éç·šæ€§é—œä¿‚ã€è³‡æ–™é‡ä¸å¤§      | KNN                 |
| ä½ è¦å¯è¦–åŒ–åˆ†é¡é‚è¼¯ã€è™•ç†è¤‡é›œé‚Šç•Œ     | Decision Tree       |
