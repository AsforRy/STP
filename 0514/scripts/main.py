# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
import os
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score, classification_report
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from imblearn.over_sampling import SMOTE
import warnings

warnings.filterwarnings("ignore")
os.environ["JOBLIB_MULTIPROCESSING"] = "0"
os.makedirs("../results", exist_ok=True)

# === å®šç¾©æ¨¡å‹ ===
models = {
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier(),
    "SVM": SVC(),
    "KNN": KNeighborsClassifier(),
    "XGBoost": XGBClassifier(eval_metric='logloss'),
    "LightGBM": LGBMClassifier(verbose=-1, force_col_wise=True, n_jobs=1),
    "CatBoost": CatBoostClassifier(verbose=0, save_snapshot=False)
}

# === åƒæ•¸ç¶²æ ¼ ===
param_grids = {
    "Decision Tree": {"max_depth": [3, 5, 10, None], "min_samples_split": [2, 5, 10]},
    "Random Forest": {"n_estimators": [50, 100], "max_depth": [5, 10, None]},
    "SVM": {"C": [0.1, 1, 10], "kernel": ['linear', 'rbf']},
    "KNN": {"n_neighbors": [3, 5, 7], "weights": ['uniform', 'distance']},
    "XGBoost": {"n_estimators": [50, 100], "max_depth": [3, 5], "learning_rate": [0.1, 0.01]},
    "LightGBM": {"n_estimators": [50, 100], "max_depth": [-1, 5, 10], "learning_rate": [0.1, 0.01]},
    "CatBoost": {"depth": [4, 6], "learning_rate": [0.1, 0.01]}
}

# === çµæœå„²å­˜ ===
results = []
report_texts = []

def evaluate_and_log(model, name, X_train, X_test, y_train, y_test, param_grid=None):
    if param_grid:
        try:
            grid = GridSearchCV(model, param_grid, cv=3, scoring='f1', n_jobs=-1)
            grid.fit(X_train, y_train)
            model = grid.best_estimator_
            print(f"âœ“ {name} ä½¿ç”¨æœ€ä½³åƒæ•¸: {grid.best_params_}")
        except Exception as e:
            print(f"âš  {name} GridSearch å¤±æ•—ï¼Œä½¿ç”¨é è¨­åƒæ•¸: {e}")
            model.fit(X_train, y_train)
    else:
        model.fit(X_train, y_train)

    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    results.append({"Model": name, "Accuracy": acc, "F1 Score": f1})
    report = classification_report(y_test, y_pred)
    report_texts.append(f"==== {name} ====" + "\n" + report + "\n")
    print(f"{name} å®Œæˆ âœ“")
    print(report)
    print("=" * 60)

# === è¼‰å…¥èˆ‡é è™•ç†è³‡æ–™é›† ===
datasets = {
    "Wine Quality": pd.read_csv("../data/wine_processed.csv"),
    "Heart Disease": pd.read_csv("../data/heart_processed.csv"),
    "Breast Cancer": pd.read_csv("../data/breast_cancer_processed.csv")
}

# === ä¸»è¿´åœˆ ===
use_gridsearch = True
use_smote = True

for dataset_name, df in datasets.items():
    X = df.drop("target", axis=1)
    y = df["target"]

    print(f"\nğŸ“Š è³‡æ–™é›†ï¼š{dataset_name}")
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    if use_smote:
        smote = SMOTE(random_state=42)
        X_train, y_train = smote.fit_resample(X_train, y_train)
        print(f"ğŸ“Œ å·²å°è¨“ç·´è³‡æ–™ä½¿ç”¨ SMOTEï¼ˆ{dataset_name}ï¼‰")

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    for name, model in models.items():
        param_grid = param_grids.get(name) if use_gridsearch else None
        if name in ["SVM", "KNN"]:
            evaluate_and_log(model, f"{dataset_name} - {name}", X_train_scaled, X_test_scaled, y_train, y_test, param_grid)
        else:
            evaluate_and_log(model, f"{dataset_name} - {name}", X_train, X_test, y_train, y_test, param_grid)

# === åŒ¯å‡ºçµæœ ===
results_df = pd.DataFrame(results)
results_df[["Dataset", "Model"]] = results_df["Model"].str.extract(r'(.*) - (.*)')
results_df = results_df.sort_values(by=["Dataset", "F1 Score"], ascending=[True, False])
results_df.to_csv("../results/comparison_results.csv", index=False, encoding="utf-8-sig")

with open("../results/classification_report.txt", "w", encoding="utf-8") as f:
    f.writelines(report_texts)

print("\nğŸ“Š æ¨¡å‹æ•ˆèƒ½ç¸½æ¯”è¼ƒï¼š")
print(results_df.to_string(index=False))
print("\nâœ… æ‰€æœ‰çµæœå·²å„²å­˜è‡³ 'results/' è³‡æ–™å¤¾")
