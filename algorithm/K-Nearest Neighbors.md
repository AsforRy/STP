# 📘K-最近鄰(K-Nearest Neighbors)

KNN 並不是一種傳統意義上的「學習型」演算法，它屬於 懶惰學習（lazy learning）：

- 它不會主動建立模型

- 而是在預測時，直接根據資料集中的 K 筆最接近的資料來判斷類別或數值

---

## 🧠 什麼是 KNN？
KNN 是一種基於距離衡量的監督式學習演算法，主要用來解決分類與回歸問題（但多數應用於分類）。它的核心理念很簡單：

>「一筆新資料的類別，可以由它附近的 K 筆資料的類別來決定。」

這就像我們在生活中會根據鄰居的特徵來推測一個人的身分或喜好

## ⚙️ KNN 的核心原理（分類版）
1. 計算距離：
> 對於一筆要預測的資料點，計算它與訓練集中每一筆資料的距離。
常用的距離有：

- 歐氏距離（最常見）

- 曼哈頓距離

- 餘弦相似度（文字資料）

2. 找出 K 個最近的鄰居：
> 挑選距離最短的 K 筆資料，稱為「最近鄰居」。

3. 投票決定類別：
> 這 K 筆鄰居中出現次數最多的類別，會被當作新資料的預測結果（多數決）