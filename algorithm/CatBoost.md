# CatBoost 

一種基於決策樹的梯度提升演算法（Gradient Boosting Decision Tree，GBDT）  
名稱來自於「Category + Boosting」

- 擅長處理**分類型資料（categorical features）**，並提供高度的預測準確度與穩定性

- 屬於先進的梯度提升樹模型，擁有出色的預測效能

適合用於實務應用中**結構化資料（如表格型資料**的分析與建模

---

## 原理

1. Ordered Target Statistics（有序目標統計）

    傳統的類別特徵通常需透過 One-Hot Encoding 或 Label Encoding，但這些方式容易造成高維度或過擬合問題  
    CatBoost 使用「有序目標統計」，依據樣本順序對類別做編碼，避免資訊洩漏（information leakage），也能降低過擬合的風險

2. Ordered Boosting（有序提升）

    傳統 GBDT 中每一棵樹會依賴上一棵樹的預測結果，這可能導致預測偏差。CatBoost 引入「有序提升」，以一種無偏的方式構建每棵樹，使模型更穩定、準確

3. 對稱樹（Symmetric Tree）

    CatBoost 所建構的樹具有固定的結構（例如每層分裂條件一致），這種對稱性讓模型預測更快、效能更穩定，尤其對於小型到中型資料集非常有效

## 優點

| 優點                | 說明                    |
| ----------------- | --------------------- |
| ✅ 原生支援類別型資料       | 不需手動編碼，模型自動處理         |
| ✅ 減少過擬合           | 尤其在樣本數較少的資料集中表現穩定     |
| ✅ 高預測準確率          | 在多個 benchmark 測試中表現優異 |
| ✅ 支援 GPU 加速       | 可顯著加快訓練速度             |
| ✅ 不需大量參數調整        | 預設參數即具備良好表現           |
| ✅ 提供 SHAP 等模型解釋工具 | 有助於提升模型透明度            |

## 缺點

| 缺點                 | 說明                                |
| ------------------ | --------------------------------- |
| ❌ 訓練時間略高於 LightGBM | 對於極大型資料集可能需更多時間                   |
| ❌ 記憶體需求偏高          | 對於資源有限的環境需特別留意                    |
| ❌ 模型結構較難解釋         | 雖有解釋工具，但不如單棵決策樹直觀                 |
| ❌ 學習曲線稍高           | 初次使用者需理解其內部邏輯（如 ordered boosting） |

## 應用場景

- 信用評分（Credit Scoring）

- 顧客流失預測（Churn Prediction）

- 疾病診斷模型（Medical Diagnosis）

- 網站點擊率預測（CTR Prediction）

- 資料科學競賽（如 Kaggle、DrivenData）

---

## 範例 : 預測是否會買產品（購物預測）

某家電商平台希望預測顧客是否會購買某一款新推出的商品。他們蒐集了以下資料：

| 顧客年齡 | 性別  | 是否為會員 | 最近一週點擊次數 | 是否購買 |
| ---- | --- | ----- | -------- | ---- |
| 25   | 女   | 是     | 10       | 是    |
| 40   | 男   | 否     | 2        | 否    |
| 31   | 女   | 是     | 5        | 是    |
| ...  | ... | ...   | ...      | ...  |

其中，「性別」和「是否為會員」是分類資料（文字類別），其他則為數值資料

### 模型選擇

使用 CatBoost 來建立預測模型的理由有：

- 不需要對「性別」「是否為會員」這類文字做額外轉換（CatBoost 自動處理）

- 資料量中等，不需要大規模分散運算

- 模型穩定性高，適合拿來做實際的預測部署

### 處理資料

1. 它會自動將「性別」與「是否為會員」轉換成內部數值，使用一種叫「有序統計」的方式進行處理，避免讓模型提前看到答案（資訊洩漏）

2. 利用梯度提升樹的方式，不斷優化錯誤預測的資料

3. 輸出結果是「購買」或「不購買」的分類結果，並可給出機率（例如「80% 會購買」）

### 模型結果應用：

- 若預測某用戶購買機率高，可推薦優惠券提高轉換率

- 若購買機率低，可用於 remarketing 策略調整